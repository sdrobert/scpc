name: model_params  # String identifier for this object.
input_size: 1 # Size of input feature dimension (1 for raw)
latent_type: conv # Which encoder to use for the 'latent' part of the model. 'conv' is convolutional; 'id' is identity (noop)
context_type: csa # Which encoder to use for the 'context' part of the model. 'csa' is causal self-atttention; 'sa' is self-attention (non-causal); 'recur' is recurrent; 'id' is identity (noop)
conv:
  name: conv  # String identifier for this object.
  output_size: 256 # Size of output (and # of conv output channels)
  channel_norm_eps: 1e-05 # Minimum denominator value in channel norm
csa:
  name: csa  # String identifier for this object.
  num_layers: 1 # Number of self-attention layers
  num_heads: 1 # Number of attention heads
  dim_feedforward: 1 # Size of intermediate representation
  layer_norm_eps: 1e-05 # Minimum denominator value in layer norm
  max_width: # Max number of past frames to attend to. Unspecified = all
sa:
  name: sa  # String identifier for this object.
  num_layers: 1 # Number of self-attention layers
  num_heads: 1 # Number of attention heads
  dim_feedforward: 1 # Size of intermediate representation
  layer_norm_eps: 1e-05 # Minimum denominator value in layer norm
recur:
  name: recur  # String identifier for this object.
  output_size: 256 # Size of output (and hidden size)
  num_layers: 1 # Number of recurrent layers
  recurrent_type: gru # Type of recurrent cell
training:
  name: training  # String identifier for this object.
  optimizer: adam # Optimizer class
  learning_rate: 0.0002 # Learning rate
  dropout_prob: 0.1 # Probability of dropping out a unit
  chunking:
    name: chunking  # String identifier for this object.
    policy: fixed # Chunking policy. 'none' for no chunking; 'fixed' for fixed window; 'ali' for sequential segments in utterance partition (requires ali/); and 'ref' for possibly overlapping segments in utterance (requires ref/)
    window_type: causal # Chunking window type. 'causal' uses past frames; 'future' uses future frames; 'symmetric' uses both (doubling window size)
    lobe_size: 20479 # Size of chunking window lobe. Frames for 'fixed' and 'ref' policies; segments for 'ali'
    pad_mode: valid # How to pad chunks exceeding utterance boundaries. 'valid' means throw away any such chunks; 'constant' pad with pad_constant; 'reflect' pad with values reflected around boundaries; 'replicate' pad by replicating boundary values
    pad_constant: 0.0 # Value to pad with when pad_mode is 'constant'
  loss_type: cpc  # Loss to train model with
  cpc_loss:
    name: cpc_loss  # String identifier for this object.
    prediction_steps: 12 # Number of frames ahead to try and predict
    negative_samples: 128 # Number of negative samples to estimate with
    num_sources: 0 # Number of sources to construct embeddings for. Source hashes will be extracted from utterance ids. 0 means no embeddings will be used
    source_regex: ^lbi-([^-]+)-.*$ # Regular expression to extract speaker id from utterance id. Must contain one group to be used as the speaker id. Will be hashed
