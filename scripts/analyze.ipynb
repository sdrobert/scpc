{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis code\n",
    "\n",
    "Code for stats + figures for paper.\n",
    "\n",
    "Run this notebook from the `scripts` folder. Prior to doing so, ensure all\n",
    "experiment artifacts have been downloaded into the `exp` folder. It should look\n",
    "like\n",
    "\n",
    "``` text\n",
    "exp/\n",
    "  bestrq.csa2/\n",
    "    version_0101/\n",
    "  bestrq.csa4/\n",
    "  ...\n",
    "```\n",
    "\n",
    "Figures are saved in the `resources` folder, not inline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble (always run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import pingouin as pg\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme('paper', font_scale=2)\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "from exp_utils import *\n",
    "\n",
    "WIDTHS = (2, 4, 8, 16, 32, 64, 128)\n",
    "STEPS = (1, 3, 6, 12, 24)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZeroSpeech ABX-LS analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zrc.subset</th>\n",
       "      <th>zrc.speaker_mode</th>\n",
       "      <th>zrc.context_mode</th>\n",
       "      <th>zrc.granularity</th>\n",
       "      <th>zrc.score</th>\n",
       "      <th>zrc.pooling</th>\n",
       "      <th>zrc.seed</th>\n",
       "      <th>zrc.pca_style</th>\n",
       "      <th>name</th>\n",
       "      <th>feat_type</th>\n",
       "      <th>...</th>\n",
       "      <th>training.best_rq_loss.mask_prob</th>\n",
       "      <th>training.best_rq_loss.mask_width</th>\n",
       "      <th>training.best_rq_loss.codebook_size</th>\n",
       "      <th>training.best_rq_loss.codebook_dim</th>\n",
       "      <th>training.best_rq_loss.offset</th>\n",
       "      <th>training.best_rq_loss.speaker_regex</th>\n",
       "      <th>training.best_rq_loss.prediction_type</th>\n",
       "      <th>training.shuffle</th>\n",
       "      <th>training.max_epochs</th>\n",
       "      <th>training.early_stopping_patience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev-clean</td>\n",
       "      <td>within</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev-clean</td>\n",
       "      <td>across</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.3216</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev-other</td>\n",
       "      <td>within</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev-other</td>\n",
       "      <td>across</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.3732</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test-clean</td>\n",
       "      <td>within</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test-clean</td>\n",
       "      <td>across</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test-other</td>\n",
       "      <td>within</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test-other</td>\n",
       "      <td>across</td>\n",
       "      <td>within</td>\n",
       "      <td>triphone</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dev-clean</td>\n",
       "      <td>within</td>\n",
       "      <td>within</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dev-clean</td>\n",
       "      <td>across</td>\n",
       "      <td>within</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>none</td>\n",
       "      <td>3459</td>\n",
       "      <td>full</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zrc.subset zrc.speaker_mode zrc.context_mode zrc.granularity  zrc.score  \\\n",
       "0   dev-clean           within           within        triphone     0.1784   \n",
       "1   dev-clean           across           within        triphone     0.3216   \n",
       "2   dev-other           within           within        triphone     0.2102   \n",
       "3   dev-other           across           within        triphone     0.3732   \n",
       "4  test-clean           within           within        triphone     0.1809   \n",
       "5  test-clean           across           within        triphone     0.3077   \n",
       "6  test-other           within           within        triphone     0.2259   \n",
       "7  test-other           across           within        triphone     0.3804   \n",
       "8   dev-clean           within           within         phoneme     0.1268   \n",
       "9   dev-clean           across           within         phoneme     0.2534   \n",
       "\n",
       "  zrc.pooling zrc.seed zrc.pca_style                        name feat_type  \\\n",
       "0        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "1        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "2        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "3        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "4        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "5        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "6        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "7        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "8        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "9        none     3459          full  bestrq.csa128/version_0101  fbank-80   \n",
       "\n",
       "   ... training.best_rq_loss.mask_prob  training.best_rq_loss.mask_width  \\\n",
       "0  ...                            0.01                              12.0   \n",
       "1  ...                            0.01                              12.0   \n",
       "2  ...                            0.01                              12.0   \n",
       "3  ...                            0.01                              12.0   \n",
       "4  ...                            0.01                              12.0   \n",
       "5  ...                            0.01                              12.0   \n",
       "6  ...                            0.01                              12.0   \n",
       "7  ...                            0.01                              12.0   \n",
       "8  ...                            0.01                              12.0   \n",
       "9  ...                            0.01                              12.0   \n",
       "\n",
       "  training.best_rq_loss.codebook_size training.best_rq_loss.codebook_dim  \\\n",
       "0                              8192.0                               16.0   \n",
       "1                              8192.0                               16.0   \n",
       "2                              8192.0                               16.0   \n",
       "3                              8192.0                               16.0   \n",
       "4                              8192.0                               16.0   \n",
       "5                              8192.0                               16.0   \n",
       "6                              8192.0                               16.0   \n",
       "7                              8192.0                               16.0   \n",
       "8                              8192.0                               16.0   \n",
       "9                              8192.0                               16.0   \n",
       "\n",
       "   training.best_rq_loss.offset  training.best_rq_loss.speaker_regex  \\\n",
       "0                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "1                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "2                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "3                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "4                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "5                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "6                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "7                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "8                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "9                           0.0                     ^lbi-([^-]+)-.*$   \n",
       "\n",
       "  training.best_rq_loss.prediction_type  training.shuffle training.max_epochs  \\\n",
       "0                                   csa             False                 200   \n",
       "1                                   csa             False                 200   \n",
       "2                                   csa             False                 200   \n",
       "3                                   csa             False                 200   \n",
       "4                                   csa             False                 200   \n",
       "5                                   csa             False                 200   \n",
       "6                                   csa             False                 200   \n",
       "7                                   csa             False                 200   \n",
       "8                                   csa             False                 200   \n",
       "9                                   csa             False                 200   \n",
       "\n",
       "  training.early_stopping_patience  \n",
       "0                               10  \n",
       "1                               10  \n",
       "2                               10  \n",
       "3                               10  \n",
       "4                               10  \n",
       "5                               10  \n",
       "6                               10  \n",
       "7                               10  \n",
       "8                               10  \n",
       "9                               10  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load zrc data\n",
    "dfz = collate_data()\n",
    "dfz.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores across subsets and context windows w/ phoneme granularity, within-speaker\n",
    "\n",
    "fig = plt.figure(figsize=[14, 4.8])\n",
    "df = filter_data_equal(dfz, {\n",
    "    \"zrc.pca_style\": \"full\",\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.cpc_loss.prediction_steps\": 12,\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    \"training.cpc_loss.negative_samples\": 128,\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"zrc.granularity\": \"phoneme\",\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"train_part\": \"100\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ")\n",
    "check_data(\n",
    "    df,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\",\n",
    "    \"zrc.context_mode\", \"zrc.speaker_mode\",\n",
    ")\n",
    "\n",
    "# 5 seeds * 7 context widths * 2 context modes * 2 speaker modes * 4 partitions\n",
    "assert len(df) == 5 * 7 * 2 * 2 * 4\n",
    "\n",
    "df['zrc.context_mode'] = df['zrc.context_mode'].map({'within': 'within', 'any': 'without'})\n",
    "\n",
    "# df = df[['name', 'csa.max_width', 'zrc.subset', 'zrc.context_mode', 'zrc.speaker_mode', 'zrc.score']]\n",
    "\n",
    "df[\"zrc.speaker_mode\"] = df['zrc.speaker_mode'].map({\n",
    "    'within': \"within speaker\",\n",
    "    \"across\": \"across speaker\"\n",
    "})\n",
    "\n",
    "# df['zrc.context_mode'] = df['zrc.context_mode'].map({\n",
    "#     'within': 'within phoneme',\n",
    "#     'any': 'without phoneme'\n",
    "# })\n",
    "\n",
    "# add dev vs test distinction to dodge on graph\n",
    "df['dvt'] = df['zrc.subset'].map({\n",
    "        'test-clean': 'test-*',\n",
    "        'test-other': 'test-*',\n",
    "        'dev-clean':  'dev-*',\n",
    "        'dev-other':  'dev-*'\n",
    "})\n",
    "\n",
    "# clean vs other\n",
    "df['cvo'] = df['zrc.subset'].map({\n",
    "        'test-clean': '*-clean',\n",
    "        'test-other': '*-other',\n",
    "        'dev-clean':  '*-clean',\n",
    "        'dev-other':  '*-other'\n",
    "})\n",
    "\n",
    "# offset the dev/test distinction ever-so-slightly to reduce overplotting\n",
    "df.loc[df['dvt'] == 'dev-*', 'csa.max_width'] *= 0.95\n",
    "df.loc[df['dvt'] == 'test-*', 'csa.max_width'] *= 1.05\n",
    "\n",
    "# ensure each point in a vertical slice gets its own error bar\n",
    "df['sbyc'] = df.agg(\"{0[zrc.subset]}-{0[zrc.context_mode]}\".format, axis=1)\n",
    "\n",
    "plot = (\n",
    "    so.Plot(df, x=\"csa.max_width\", y=\"zrc.score\", color=\"zrc.context_mode\", marker=\"cvo\", fill='dvt', group='sbyc')\n",
    "    .facet(\"zrc.speaker_mode\")\n",
    "    .limit(y=(0.05, 0.26))\n",
    "    .add(so.Dot(pointsize=7), so.Agg())\n",
    "    .add(so.Range(), so.Est(errorbar=\"se\"), legend=False)  # 1 standard error\n",
    "    # .add(so.Line(marker=None), so.PolyFit())  # misleading?\n",
    "    .scale(\n",
    "        x=(\n",
    "            so.Continuous(trans=\"log\")\n",
    "            .tick(at=[2, 4, 8, 16, 32, 64, 128])\n",
    "            .label(like='d', base=2)\n",
    "        ),\n",
    "        y=(\n",
    "            so.Continuous()\n",
    "            .tick(at=[0.05, 0.1, 0.15, 0.2, 0.25])\n",
    "            .label(like='.0%')\n",
    "        ),\n",
    "    )\n",
    "    .label(x=\"width\", y=\"ABX error rate\")\n",
    "    .on(fig)\n",
    ")\n",
    "\n",
    "plotter = plot.plot()\n",
    "\n",
    "# for ax in fig.axes:\n",
    "#     box = ax.get_position()\n",
    "#     ax.set_position([box.x0 - box.width * 0.15, box.y0 + box.height * 0.13,\n",
    "#                     1.15 * box.width, box.height * 0.96])\n",
    "\n",
    "legend_contents = plotter._legend_contents\n",
    "fig.legends.pop(0)\n",
    "handles = []\n",
    "labels = []\n",
    "for i, legend_content in enumerate(legend_contents):\n",
    "    if i == 0:\n",
    "        loc, x = 'upper left', 0.15\n",
    "    elif i == 1:\n",
    "        loc, x = 'upper center', 0.52\n",
    "    else:\n",
    "        loc, x = 'upper right', 0.9\n",
    "    fig.legend(\n",
    "        legend_content[1], legend_content[2],\n",
    "        ncol=2, fontsize='x-small', loc='upper center', columnspacing=1,\n",
    "        handletextpad=0.1, bbox_to_anchor=(x, 0.25))\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../resources/libriabx_context_subset_phoneme.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============\n",
      "ANOVA SUMMARY\n",
      "=============\n",
      "\n",
      "Source           ddof1    ddof2      F    p-unc    np2\n",
      "-------------  -------  -------  -----  -------  -----\n",
      "csa.max_width        6       28  6.026    0.000  0.564\n",
      "\n",
      "    W    pval  normal\n",
      "-----  ------  --------\n",
      "0.874   0.282  True\n",
      "0.932   0.609  True\n",
      "0.832   0.145  True\n",
      "0.862   0.236  True\n",
      "0.954   0.765  True\n",
      "0.874   0.284  True\n",
      "0.969   0.869  True\n",
      "\n",
      "    W    pval  equal_var\n",
      "-----  ------  -----------\n",
      "0.826   0.560  True\n",
      "\n",
      "\n",
      "==============\n",
      "POST HOC TESTS\n",
      "==============\n",
      "\n",
      "Contrast         A    B    mean(A)    std(A)    mean(B)    std(B)  Paired    Parametric      U-val  alternative      p-unc    hedges\n",
      "-------------  ---  ---  ---------  --------  ---------  --------  --------  ------------  -------  -------------  -------  --------\n",
      "csa.max_width    2    4      0.156     0.003      0.142     0.013  False     False          22.000  two-sided        0.056     1.338\n",
      "csa.max_width    2    8      0.156     0.003      0.151     0.012  False     False          14.000  two-sided        0.841     0.495\n",
      "csa.max_width    2   16      0.156     0.003      0.153     0.010  False     False          14.000  two-sided        0.841     0.364\n",
      "csa.max_width    2   32      0.156     0.003      0.148     0.014  False     False          20.000  two-sided        0.151     0.676\n",
      "csa.max_width    2   64      0.156     0.003      0.169     0.006  False     False           0.000  two-sided        0.008    -2.429\n",
      "csa.max_width    2  128      0.156     0.003      0.177     0.015  False     False           1.000  two-sided        0.016    -1.783\n",
      "csa.max_width    4    8      0.142     0.013      0.151     0.012  False     False           8.000  two-sided        0.421    -0.640\n",
      "csa.max_width    4   16      0.142     0.013      0.153     0.010  False     False           5.000  two-sided        0.151    -0.854\n",
      "csa.max_width    4   32      0.142     0.013      0.148     0.014  False     False          10.000  two-sided        0.690    -0.427\n",
      "csa.max_width    4   64      0.142     0.013      0.169     0.006  False     False           0.000  two-sided        0.008    -2.423\n",
      "csa.max_width    4  128      0.142     0.013      0.177     0.015  False     False           0.000  two-sided        0.008    -2.281\n",
      "csa.max_width    8   16      0.151     0.012      0.153     0.010  False     False          10.000  two-sided        0.690    -0.158\n",
      "csa.max_width    8   32      0.151     0.012      0.148     0.014  False     False          14.000  two-sided        0.841     0.179\n",
      "csa.max_width    8   64      0.151     0.012      0.169     0.006  False     False           2.000  two-sided        0.032    -1.676\n",
      "csa.max_width    8  128      0.151     0.012      0.177     0.015  False     False           2.000  two-sided        0.032    -1.735\n",
      "csa.max_width   16   32      0.153     0.010      0.148     0.014  False     False          16.000  two-sided        0.548     0.340\n",
      "csa.max_width   16   64      0.153     0.010      0.169     0.006  False     False           2.000  two-sided        0.032    -1.759\n",
      "csa.max_width   16  128      0.153     0.010      0.177     0.015  False     False           2.000  two-sided        0.032    -1.731\n",
      "csa.max_width   32   64      0.148     0.014      0.169     0.006  False     False           2.000  two-sided        0.032    -1.740\n",
      "csa.max_width   32  128      0.148     0.014      0.177     0.015  False     False           2.000  two-sided        0.032    -1.811\n",
      "csa.max_width   64  128      0.169     0.006      0.177     0.015  False     False           8.000  two-sided        0.421    -0.659\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# determine significance of context windows\n",
    "\n",
    "df = filter_data_equal(dfz, {\n",
    "    \"zrc.pca_style\": \"full\",\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.cpc_loss.prediction_steps\": 12,\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    \"training.cpc_loss.negative_samples\": 128,\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"zrc.granularity\": \"phoneme\",\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    # \"zrc.speaker_mode\": \"within\",\n",
    "    \"train_part\": '100',\n",
    "    # \"zrc.context_mode\": \"within\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ")\n",
    "check_data(\n",
    "    df,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\", \"zrc.speaker_mode\", \"zrc.context_mode\"\n",
    ")\n",
    "\n",
    "# 5 seeds * 7 context widths * 4 partitions\n",
    "assert len(df) == 5 * 7 * 4 * 4\n",
    "\n",
    "df = df[['name', 'csa.max_width', 'zrc.score']].groupby('name', as_index=False, observed=True, sort=True).mean(numeric_only=True)\n",
    "df['csa.max_width'] = df['csa.max_width'].astype('int').astype('category')\n",
    "\n",
    "pg.print_table(pg.anova(data=df, dv='zrc.score', between='csa.max_width'))\n",
    "pg.print_table(pg.normality(data=df, dv='zrc.score', group='csa.max_width'))\n",
    "pg.print_table(pg.homoscedasticity(data=df, dv='zrc.score', group='csa.max_width'))\n",
    "\n",
    "pg.print_table(pg.pairwise_tests(data=df, dv='zrc.score', between='csa.max_width', parametric=False, return_desc=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot libriABX score of context width vs prediction steps (averaged)\n",
    "# - this one will show up on the left of our figure, so it doesn't have the cbar\n",
    "#   but does have the y axis label\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 4.8), sharey=True)\n",
    "\n",
    "df = filter_data_equal(dfz, {\n",
    "    \"zrc.pca_style\": \"full\",\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"zrc.granularity\": \"phoneme\",\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    # \"zrc.speaker_mode\": \"within\",\n",
    "    # \"zrc.context_mode\": \"within\",\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"train_part\": \"100\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\n",
    "        \"csa.max_width\": WIDTHS,\n",
    "        \"training.cpc_loss.prediction_steps\": STEPS,\n",
    "    }\n",
    ")\n",
    "check_data(\n",
    "    df,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\",\n",
    "    \"zrc.context_mode\", \"zrc.speaker_mode\",\n",
    "    \"training.cpc_loss.prediction_steps\"\n",
    ")\n",
    "df = df.pivot_table(\n",
    "    columns=\"csa.max_width\",\n",
    "    index=\"training.cpc_loss.prediction_steps\",\n",
    "    values=\"zrc.score\"\n",
    ").sort_values(by='training.cpc_loss.prediction_steps', ascending=False)\n",
    "plot = sns.heatmap(df, annot=True, fmt=\".0%\", vmin=0.1, vmax=0.5, cbar=False, square=True, ax=axs[0])\n",
    "plot.set(xlabel='context width', ylabel='prediction steps', title='averaged')\n",
    "plot.set_xticklabels([f'{int(x):d}' for x in sorted(df.columns)])\n",
    "\n",
    "df = filter_data_equal(dfz, {\n",
    "    \"zrc.pca_style\": \"full\",\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"training.cpc_loss.negative_samples\": 128,\n",
    "    \"zrc.granularity\": \"phoneme\",\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"train_part\": \"100\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ")\n",
    "idx = df['training.cpc_loss.prediction_steps'] == 1\n",
    "for n in range(2, 25):\n",
    "    idx |= (df['training.cpc_loss.prediction_steps'] == n) & (df['training.cpc_loss.gutted_steps'] == (n - 1))\n",
    "df = df.loc[idx]\n",
    "check_data(\n",
    "    df,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\",\n",
    "    \"zrc.context_mode\", \"zrc.speaker_mode\",\n",
    "    \"training.cpc_loss.prediction_steps\",\n",
    "    \"training.cpc_loss.gutted_steps\",\n",
    ")\n",
    "df = df.pivot_table(\n",
    "    columns=\"csa.max_width\",\n",
    "    index=\"training.cpc_loss.prediction_steps\",\n",
    "    values=\"zrc.score\"\n",
    ").sort_values(by='training.cpc_loss.prediction_steps', ascending=False)\n",
    "plot = sns.heatmap(df, annot=True, fmt=\".0%\", vmin=0.1, vmax=0.5, square=True, cbar=False, ax=axs[1])\n",
    "plot.set(xlabel='context width', ylabel=None, title='last')\n",
    "plot.set_xticklabels([f'{int(x):d}' for x in sorted(df.columns)])\n",
    "plot.set_yticklabels([f'{int(x):d}' for x in sorted(df.index, reverse=True)])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"../resources/libriabx_prediction_steps_vs_width.pdf\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4ba56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >training.cpc_loss.prediction_steps</th>\n",
       "      <th id=\"T_4ba56_level0_col0\" class=\"col_heading level0 col0\" >1</th>\n",
       "      <th id=\"T_4ba56_level0_col1\" class=\"col_heading level0 col1\" >3</th>\n",
       "      <th id=\"T_4ba56_level0_col2\" class=\"col_heading level0 col2\" >6</th>\n",
       "      <th id=\"T_4ba56_level0_col3\" class=\"col_heading level0 col3\" >12</th>\n",
       "      <th id=\"T_4ba56_level0_col4\" class=\"col_heading level0 col4\" >24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4ba56_level0_row0\" class=\"row_heading level0 row0\" >averaged</th>\n",
       "      <td id=\"T_4ba56_row0_col0\" class=\"data row0 col0\" >43.8</td>\n",
       "      <td id=\"T_4ba56_row0_col1\" class=\"data row0 col1\" >26.1</td>\n",
       "      <td id=\"T_4ba56_row0_col2\" class=\"data row0 col2\" >16.6</td>\n",
       "      <td id=\"T_4ba56_row0_col3\" class=\"data row0 col3\" >15.7</td>\n",
       "      <td id=\"T_4ba56_row0_col4\" class=\"data row0 col4\" >20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4ba56_level0_row1\" class=\"row_heading level0 row1\" >last</th>\n",
       "      <td id=\"T_4ba56_row1_col0\" class=\"data row1 col0\" >43.8</td>\n",
       "      <td id=\"T_4ba56_row1_col1\" class=\"data row1 col1\" >17.5</td>\n",
       "      <td id=\"T_4ba56_row1_col2\" class=\"data row1 col2\" >14.4</td>\n",
       "      <td id=\"T_4ba56_row1_col3\" class=\"data row1 col3\" >16.0</td>\n",
       "      <td id=\"T_4ba56_row1_col4\" class=\"data row1 col4\" >31.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28d8f00fbe0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate prediction steps over context widths and print as table\n",
    "\n",
    "df = filter_data_equal(dfz, {\n",
    "    \"zrc.pca_style\": \"full\",\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"zrc.granularity\": \"phoneme\",\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"train_part\": \"100\",\n",
    "})\n",
    "\n",
    "df_1 = filter_data_in(\n",
    "    df, {\n",
    "        \"csa.max_width\": WIDTHS,\n",
    "        \"training.cpc_loss.prediction_steps\": STEPS,\n",
    "        \"training.cpc_loss.gutted_steps\": (0,),\n",
    "    }\n",
    ")\n",
    "check_data(\n",
    "    df_1,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\",\n",
    "    \"zrc.context_mode\", \"zrc.speaker_mode\",\n",
    "    \"training.cpc_loss.prediction_steps\"\n",
    ")\n",
    "df_1.loc[:, 'name'] = 'averaged'\n",
    "\n",
    "df_2 = filter_data_in(\n",
    "    df, {\n",
    "        \"csa.max_width\": WIDTHS,\n",
    "        \"training.cpc_loss.prediction_steps\": STEPS,\n",
    "    }\n",
    ")\n",
    "idx = df_2['training.cpc_loss.prediction_steps'] == 1\n",
    "for n in range(2, 25):\n",
    "    idx |= (df_2['training.cpc_loss.prediction_steps'] == n) & (df_2['training.cpc_loss.gutted_steps'] == (n - 1))\n",
    "df_2 = df_2.loc[idx]\n",
    "check_data(\n",
    "    df_2,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\",\n",
    "    \"zrc.context_mode\", \"zrc.speaker_mode\",\n",
    "    \"training.cpc_loss.prediction_steps\",\n",
    "    \"training.cpc_loss.gutted_steps\",\n",
    ")\n",
    "df_2.loc[:, 'name'] = 'last'\n",
    "\n",
    "df = pd.concat([df_1, df_2])\n",
    "df['training.cpc_loss.prediction_steps'] = df['training.cpc_loss.prediction_steps'].astype('int')\n",
    "df = pd.pivot_table(df, values='zrc.score', columns='training.cpc_loss.prediction_steps', index='name')\n",
    "\n",
    "(df * 100).style.format(precision=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cbfd3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >csa.max_width</th>\n",
       "      <th id=\"T_cbfd3_level0_col0\" class=\"col_heading level0 col0\" >2</th>\n",
       "      <th id=\"T_cbfd3_level0_col1\" class=\"col_heading level0 col1\" >4</th>\n",
       "      <th id=\"T_cbfd3_level0_col2\" class=\"col_heading level0 col2\" >8</th>\n",
       "      <th id=\"T_cbfd3_level0_col3\" class=\"col_heading level0 col3\" >16</th>\n",
       "      <th id=\"T_cbfd3_level0_col4\" class=\"col_heading level0 col4\" >32</th>\n",
       "      <th id=\"T_cbfd3_level0_col5\" class=\"col_heading level0 col5\" >64</th>\n",
       "      <th id=\"T_cbfd3_level0_col6\" class=\"col_heading level0 col6\" >128</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row0\" class=\"row_heading level0 row0\" >2-layer</th>\n",
       "      <td id=\"T_cbfd3_row0_col0\" class=\"data row0 col0\" >13.7</td>\n",
       "      <td id=\"T_cbfd3_row0_col1\" class=\"data row0 col1\" >15.5</td>\n",
       "      <td id=\"T_cbfd3_row0_col2\" class=\"data row0 col2\" >15.8</td>\n",
       "      <td id=\"T_cbfd3_row0_col3\" class=\"data row0 col3\" >12.6</td>\n",
       "      <td id=\"T_cbfd3_row0_col4\" class=\"data row0 col4\" >13.6</td>\n",
       "      <td id=\"T_cbfd3_row0_col5\" class=\"data row0 col5\" >16.8</td>\n",
       "      <td id=\"T_cbfd3_row0_col6\" class=\"data row0 col6\" >13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row1\" class=\"row_heading level0 row1\" >4-layer</th>\n",
       "      <td id=\"T_cbfd3_row1_col0\" class=\"data row1 col0\" >13.8</td>\n",
       "      <td id=\"T_cbfd3_row1_col1\" class=\"data row1 col1\" >13.0</td>\n",
       "      <td id=\"T_cbfd3_row1_col2\" class=\"data row1 col2\" >14.1</td>\n",
       "      <td id=\"T_cbfd3_row1_col3\" class=\"data row1 col3\" >15.8</td>\n",
       "      <td id=\"T_cbfd3_row1_col4\" class=\"data row1 col4\" >15.8</td>\n",
       "      <td id=\"T_cbfd3_row1_col5\" class=\"data row1 col5\" >16.8</td>\n",
       "      <td id=\"T_cbfd3_row1_col6\" class=\"data row1 col6\" >17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row2\" class=\"row_heading level0 row2\" >960h</th>\n",
       "      <td id=\"T_cbfd3_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_cbfd3_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_cbfd3_row2_col2\" class=\"data row2 col2\" >17.2</td>\n",
       "      <td id=\"T_cbfd3_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "      <td id=\"T_cbfd3_row2_col4\" class=\"data row2 col4\" >nan</td>\n",
       "      <td id=\"T_cbfd3_row2_col5\" class=\"data row2 col5\" >nan</td>\n",
       "      <td id=\"T_cbfd3_row2_col6\" class=\"data row2 col6\" >18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row3\" class=\"row_heading level0 row3\" >BEST-RQ</th>\n",
       "      <td id=\"T_cbfd3_row3_col0\" class=\"data row3 col0\" >27.6</td>\n",
       "      <td id=\"T_cbfd3_row3_col1\" class=\"data row3 col1\" >24.1</td>\n",
       "      <td id=\"T_cbfd3_row3_col2\" class=\"data row3 col2\" >24.5</td>\n",
       "      <td id=\"T_cbfd3_row3_col3\" class=\"data row3 col3\" >26.6</td>\n",
       "      <td id=\"T_cbfd3_row3_col4\" class=\"data row3 col4\" >26.1</td>\n",
       "      <td id=\"T_cbfd3_row3_col5\" class=\"data row3 col5\" >28.0</td>\n",
       "      <td id=\"T_cbfd3_row3_col6\" class=\"data row3 col6\" >25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row4\" class=\"row_heading level0 row4\" >avg@6</th>\n",
       "      <td id=\"T_cbfd3_row4_col0\" class=\"data row4 col0\" >18.9</td>\n",
       "      <td id=\"T_cbfd3_row4_col1\" class=\"data row4 col1\" >17.2</td>\n",
       "      <td id=\"T_cbfd3_row4_col2\" class=\"data row4 col2\" >14.3</td>\n",
       "      <td id=\"T_cbfd3_row4_col3\" class=\"data row4 col3\" >16.9</td>\n",
       "      <td id=\"T_cbfd3_row4_col4\" class=\"data row4 col4\" >14.3</td>\n",
       "      <td id=\"T_cbfd3_row4_col5\" class=\"data row4 col5\" >17.5</td>\n",
       "      <td id=\"T_cbfd3_row4_col6\" class=\"data row4 col6\" >17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row5\" class=\"row_heading level0 row5\" >conv (fixed H_2)</th>\n",
       "      <td id=\"T_cbfd3_row5_col0\" class=\"data row5 col0\" >15.0</td>\n",
       "      <td id=\"T_cbfd3_row5_col1\" class=\"data row5 col1\" >14.6</td>\n",
       "      <td id=\"T_cbfd3_row5_col2\" class=\"data row5 col2\" >16.9</td>\n",
       "      <td id=\"T_cbfd3_row5_col3\" class=\"data row5 col3\" >14.2</td>\n",
       "      <td id=\"T_cbfd3_row5_col4\" class=\"data row5 col4\" >50.0</td>\n",
       "      <td id=\"T_cbfd3_row5_col5\" class=\"data row5 col5\" >22.3</td>\n",
       "      <td id=\"T_cbfd3_row5_col6\" class=\"data row5 col6\" >43.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row6\" class=\"row_heading level0 row6\" >conv (fixed size)</th>\n",
       "      <td id=\"T_cbfd3_row6_col0\" class=\"data row6 col0\" >17.0</td>\n",
       "      <td id=\"T_cbfd3_row6_col1\" class=\"data row6 col1\" >14.6</td>\n",
       "      <td id=\"T_cbfd3_row6_col2\" class=\"data row6 col2\" >16.8</td>\n",
       "      <td id=\"T_cbfd3_row6_col3\" class=\"data row6 col3\" >17.0</td>\n",
       "      <td id=\"T_cbfd3_row6_col4\" class=\"data row6 col4\" >19.0</td>\n",
       "      <td id=\"T_cbfd3_row6_col5\" class=\"data row6 col5\" >19.4</td>\n",
       "      <td id=\"T_cbfd3_row6_col6\" class=\"data row6 col6\" >20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row7\" class=\"row_heading level0 row7\" >last@6</th>\n",
       "      <td id=\"T_cbfd3_row7_col0\" class=\"data row7 col0\" >14.0</td>\n",
       "      <td id=\"T_cbfd3_row7_col1\" class=\"data row7 col1\" >13.9</td>\n",
       "      <td id=\"T_cbfd3_row7_col2\" class=\"data row7 col2\" >13.1</td>\n",
       "      <td id=\"T_cbfd3_row7_col3\" class=\"data row7 col3\" >15.4</td>\n",
       "      <td id=\"T_cbfd3_row7_col4\" class=\"data row7 col4\" >13.3</td>\n",
       "      <td id=\"T_cbfd3_row7_col5\" class=\"data row7 col5\" >14.9</td>\n",
       "      <td id=\"T_cbfd3_row7_col6\" class=\"data row7 col6\" >16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row8\" class=\"row_heading level0 row8\" >long train</th>\n",
       "      <td id=\"T_cbfd3_row8_col0\" class=\"data row8 col0\" >13.4</td>\n",
       "      <td id=\"T_cbfd3_row8_col1\" class=\"data row8 col1\" >13.0</td>\n",
       "      <td id=\"T_cbfd3_row8_col2\" class=\"data row8 col2\" >14.0</td>\n",
       "      <td id=\"T_cbfd3_row8_col3\" class=\"data row8 col3\" >14.4</td>\n",
       "      <td id=\"T_cbfd3_row8_col4\" class=\"data row8 col4\" >14.3</td>\n",
       "      <td id=\"T_cbfd3_row8_col5\" class=\"data row8 col5\" >14.7</td>\n",
       "      <td id=\"T_cbfd3_row8_col6\" class=\"data row8 col6\" >15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbfd3_level0_row9\" class=\"row_heading level0 row9\" >main</th>\n",
       "      <td id=\"T_cbfd3_row9_col0\" class=\"data row9 col0\" >15.6</td>\n",
       "      <td id=\"T_cbfd3_row9_col1\" class=\"data row9 col1\" >14.2</td>\n",
       "      <td id=\"T_cbfd3_row9_col2\" class=\"data row9 col2\" >15.1</td>\n",
       "      <td id=\"T_cbfd3_row9_col3\" class=\"data row9 col3\" >15.3</td>\n",
       "      <td id=\"T_cbfd3_row9_col4\" class=\"data row9 col4\" >14.8</td>\n",
       "      <td id=\"T_cbfd3_row9_col5\" class=\"data row9 col5\" >16.9</td>\n",
       "      <td id=\"T_cbfd3_row9_col6\" class=\"data row9 col6\" >17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28d8e8a0940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# various means for stats table\n",
    "# (main can be derived from the above figure)\n",
    "\n",
    "row2names = {\n",
    "    \"main\":  set(f'cpc.csa{w}/version_{v:04d}' for w in WIDTHS for v in range(101, 106)),\n",
    "    \"long train\": set(f'cpc.csa{w}/version_0012' for w in WIDTHS),\n",
    "    \"960h\": set(f'cpc.csa{w}/version_0003' for w in WIDTHS),\n",
    "    \"2-layer\": set(f'cpc.csa{w}/version_1001' for w in WIDTHS),\n",
    "    \"4-layer\": set(f'cpc.csa{w}/version_1101' for w in WIDTHS),\n",
    "    \"conv (fixed size)\": set(f\"cpc.cconv{w}/version_0101\" for w in WIDTHS),\n",
    "    \"conv (fixed H_2)\": set(f\"cpc.cconv{w}/version_0201\" for w in WIDTHS),\n",
    "    \"BEST-RQ\": set(f\"bestrq.csa{w}/version_0101\" for w in WIDTHS),\n",
    "    \"last@6\": set(f\"cpc.csa{w}/version_0701\" for w in WIDTHS),\n",
    "    \"avg@6\": set(f\"cpc.csa{w}/version_0201\" for w in WIDTHS),\n",
    "}\n",
    "name2row = dict()\n",
    "for row, names in row2names.items():\n",
    "    name2row.update((name, row) for name in names)\n",
    "\n",
    "df = filter_data_equal(dfz, {\"zrc.granularity\": \"phoneme\"})\n",
    "df = filter_data_in(df, {'name': set(name2row)}).copy()\n",
    "\n",
    "df['csa.max_width'] = df['csa.max_width'].where(~df['csa.max_width'].isna(), df['cconv.kernel_size']).astype('int')\n",
    "\n",
    "df['name'] = df['name'].cat.remove_unused_categories().apply(lambda x: name2row[x])\n",
    "\n",
    "\n",
    "df = pd.pivot_table(df, values='zrc.score', columns='csa.max_width', index='name')\n",
    "\n",
    "(df * 100).style.format(precision=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4de25\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4de25_level0_col0\" class=\"col_heading level0 col0\" >csa.max_width</th>\n",
       "      <th id=\"T_4de25_level0_col1\" class=\"col_heading level0 col1\" >zrc.score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >name</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row0\" class=\"row_heading level0 row0\" >cpc.csa2/version_0105</th>\n",
       "      <td id=\"T_4de25_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_4de25_row0_col1\" class=\"data row0 col1\" >15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row1\" class=\"row_heading level0 row1\" >cpc.csa4/version_0102</th>\n",
       "      <td id=\"T_4de25_row1_col0\" class=\"data row1 col0\" >4</td>\n",
       "      <td id=\"T_4de25_row1_col1\" class=\"data row1 col1\" >12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row2\" class=\"row_heading level0 row2\" >cpc.csa8/version_0101</th>\n",
       "      <td id=\"T_4de25_row2_col0\" class=\"data row2 col0\" >8</td>\n",
       "      <td id=\"T_4de25_row2_col1\" class=\"data row2 col1\" >13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row3\" class=\"row_heading level0 row3\" >cpc.csa16/version_0103</th>\n",
       "      <td id=\"T_4de25_row3_col0\" class=\"data row3 col0\" >16</td>\n",
       "      <td id=\"T_4de25_row3_col1\" class=\"data row3 col1\" >13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row4\" class=\"row_heading level0 row4\" >cpc.csa32/version_0104</th>\n",
       "      <td id=\"T_4de25_row4_col0\" class=\"data row4 col0\" >32</td>\n",
       "      <td id=\"T_4de25_row4_col1\" class=\"data row4 col1\" >13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row5\" class=\"row_heading level0 row5\" >cpc.csa64/version_0101</th>\n",
       "      <td id=\"T_4de25_row5_col0\" class=\"data row5 col0\" >64</td>\n",
       "      <td id=\"T_4de25_row5_col1\" class=\"data row5 col1\" >16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4de25_level0_row6\" class=\"row_heading level0 row6\" >cpc.csa128/version_0101</th>\n",
       "      <td id=\"T_4de25_row6_col0\" class=\"data row6 col0\" >128</td>\n",
       "      <td id=\"T_4de25_row6_col1\" class=\"data row6 col1\" >15.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28d8e694970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the mean abx error rates for the models we trained downstream ASR systems for\n",
    "# (also the the mininum ABX of the repeat trials over context widths)\n",
    "\n",
    "df = filter_data_equal(dfz, {\n",
    "    \"zrc.pca_style\": \"full\",\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.cpc_loss.prediction_steps\": 12,\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    \"training.cpc_loss.negative_samples\": 128,\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"zrc.granularity\": \"phoneme\",\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"train_part\": \"100\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ")\n",
    "check_data(\n",
    "    df,\n",
    "    \"csa.max_width\", \"zrc.subset\", \"zrc.score\", \"zrc.context_mode\", \"zrc.speaker_mode\",\n",
    ")\n",
    "\n",
    "df = df[['name', 'csa.max_width', 'zrc.score']].groupby(['name']).mean().dropna()\n",
    "# 5 seeds * 7 context widths\n",
    "assert len(df) == 5 * 7\n",
    "\n",
    "min_idxs = []\n",
    "for w in WIDTHS:\n",
    "    min_idxs.append(df[df['csa.max_width'] == w]['zrc.score'].idxmin())\n",
    "min_df_100 = df.loc[min_idxs]\n",
    "min_df_100['csa.max_width'] = min_df_100[\"csa.max_width\"].astype('int')\n",
    "min_df_100['zrc.score'] *= 100\n",
    "min_df_100.style.format(precision=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 zrc.score\n",
      "name                      \n",
      "ours              9.553125\n",
      "ours (w/o norm)  11.582500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f25a3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f25a3_level0_col0\" class=\"col_heading level0 col0\" >zrc.score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >name</th>\n",
       "      <th class=\"index_name level1\" >zrc.subset</th>\n",
       "      <th class=\"index_name level2\" >zrc.speaker_mode</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"4\">ours</th>\n",
       "      <th id=\"T_f25a3_level1_row0\" class=\"row_heading level1 row0\" rowspan=\"2\">dev-clean</th>\n",
       "      <th id=\"T_f25a3_level2_row0\" class=\"row_heading level2 row0\" >across</th>\n",
       "      <td id=\"T_f25a3_row0_col0\" class=\"data row0 col0\" >8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level2_row1\" class=\"row_heading level2 row1\" >within</th>\n",
       "      <td id=\"T_f25a3_row1_col0\" class=\"data row1 col0\" >6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level1_row2\" class=\"row_heading level1 row2\" rowspan=\"2\">dev-other</th>\n",
       "      <th id=\"T_f25a3_level2_row2\" class=\"row_heading level2 row2\" >across</th>\n",
       "      <td id=\"T_f25a3_row2_col0\" class=\"data row2 col0\" >14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level2_row3\" class=\"row_heading level2 row3\" >within</th>\n",
       "      <td id=\"T_f25a3_row3_col0\" class=\"data row3 col0\" >8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"4\">ours (w/o norm)</th>\n",
       "      <th id=\"T_f25a3_level1_row4\" class=\"row_heading level1 row4\" rowspan=\"2\">dev-clean</th>\n",
       "      <th id=\"T_f25a3_level2_row4\" class=\"row_heading level2 row4\" >across</th>\n",
       "      <td id=\"T_f25a3_row4_col0\" class=\"data row4 col0\" >12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level2_row5\" class=\"row_heading level2 row5\" >within</th>\n",
       "      <td id=\"T_f25a3_row5_col0\" class=\"data row5 col0\" >8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level1_row6\" class=\"row_heading level1 row6\" rowspan=\"2\">dev-other</th>\n",
       "      <th id=\"T_f25a3_level2_row6\" class=\"row_heading level2 row6\" >across</th>\n",
       "      <td id=\"T_f25a3_row6_col0\" class=\"data row6 col0\" >17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f25a3_level2_row7\" class=\"row_heading level2 row7\" >within</th>\n",
       "      <td id=\"T_f25a3_row7_col0\" class=\"data row7 col0\" >10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28d8e8e08e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our implementations of CPC-Small\n",
    "name2row = {\n",
    "    'cpc.small/version_1': 'ours',\n",
    "    'cpc.small/version_2': 'ours (w/o norm)'\n",
    "}\n",
    "\n",
    "df = collate_data(model_yaml_glob='cpc.small/version_[12]/model.yaml')\n",
    "df = filter_data_equal(df, {'zrc.pca_style': 'full'})\n",
    "df['name'] = df['name'].cat.remove_unused_categories().apply(lambda x: name2row[x])\n",
    "df['zrc.score'] *= 100\n",
    "\n",
    "# mean phoneme rates\n",
    "df_ = filter_data_equal(df, {'zrc.granularity': 'phoneme'})\n",
    "print(df_[['name', 'zrc.score']].groupby(['name']).mean())\n",
    "\n",
    "# rates comparable to zs 2021\n",
    "df_ = filter_data_equal(df, {'zrc.granularity': 'triphone'})\n",
    "df_ = filter_data_in(df_, {'zrc.subset': ('dev-clean', 'dev-other')})\n",
    "df_ = df_[['name', 'zrc.subset', 'zrc.speaker_mode', 'zrc.score']].groupby(['name', 'zrc.subset', 'zrc.speaker_mode']).mean().dropna()\n",
    "df_.style.format(precision=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tb.step</th>\n",
       "      <th>tb.epoch</th>\n",
       "      <th>tb.val_loss</th>\n",
       "      <th>name</th>\n",
       "      <th>feat_type</th>\n",
       "      <th>train_part</th>\n",
       "      <th>input_size</th>\n",
       "      <th>latent_type</th>\n",
       "      <th>context_type</th>\n",
       "      <th>version</th>\n",
       "      <th>...</th>\n",
       "      <th>training.best_rq_loss.mask_prob</th>\n",
       "      <th>training.best_rq_loss.mask_width</th>\n",
       "      <th>training.best_rq_loss.codebook_size</th>\n",
       "      <th>training.best_rq_loss.codebook_dim</th>\n",
       "      <th>training.best_rq_loss.offset</th>\n",
       "      <th>training.best_rq_loss.speaker_regex</th>\n",
       "      <th>training.best_rq_loss.prediction_type</th>\n",
       "      <th>training.shuffle</th>\n",
       "      <th>training.max_epochs</th>\n",
       "      <th>training.early_stopping_patience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1902</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514025</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3805</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347518</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5708</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275961</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7611</td>\n",
       "      <td>3</td>\n",
       "      <td>0.222729</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9514</td>\n",
       "      <td>4</td>\n",
       "      <td>0.198708</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11417</td>\n",
       "      <td>5</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13320</td>\n",
       "      <td>6</td>\n",
       "      <td>0.180398</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15223</td>\n",
       "      <td>7</td>\n",
       "      <td>0.164576</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17126</td>\n",
       "      <td>8</td>\n",
       "      <td>0.161085</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19029</td>\n",
       "      <td>9</td>\n",
       "      <td>0.145282</td>\n",
       "      <td>bestrq.csa128/version_0101</td>\n",
       "      <td>fbank-80</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>ff</td>\n",
       "      <td>csa</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8192.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>^lbi-([^-]+)-.*$</td>\n",
       "      <td>csa</td>\n",
       "      <td>False</td>\n",
       "      <td>200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tb.step  tb.epoch  tb.val_loss                        name feat_type  \\\n",
       "0     1902         0     0.514025  bestrq.csa128/version_0101  fbank-80   \n",
       "1     3805         1     0.347518  bestrq.csa128/version_0101  fbank-80   \n",
       "2     5708         2     0.275961  bestrq.csa128/version_0101  fbank-80   \n",
       "3     7611         3     0.222729  bestrq.csa128/version_0101  fbank-80   \n",
       "4     9514         4     0.198708  bestrq.csa128/version_0101  fbank-80   \n",
       "5    11417         5     0.202900  bestrq.csa128/version_0101  fbank-80   \n",
       "6    13320         6     0.180398  bestrq.csa128/version_0101  fbank-80   \n",
       "7    15223         7     0.164576  bestrq.csa128/version_0101  fbank-80   \n",
       "8    17126         8     0.161085  bestrq.csa128/version_0101  fbank-80   \n",
       "9    19029         9     0.145282  bestrq.csa128/version_0101  fbank-80   \n",
       "\n",
       "  train_part  input_size latent_type context_type  version  ...  \\\n",
       "0        100          80          ff          csa      101  ...   \n",
       "1        100          80          ff          csa      101  ...   \n",
       "2        100          80          ff          csa      101  ...   \n",
       "3        100          80          ff          csa      101  ...   \n",
       "4        100          80          ff          csa      101  ...   \n",
       "5        100          80          ff          csa      101  ...   \n",
       "6        100          80          ff          csa      101  ...   \n",
       "7        100          80          ff          csa      101  ...   \n",
       "8        100          80          ff          csa      101  ...   \n",
       "9        100          80          ff          csa      101  ...   \n",
       "\n",
       "   training.best_rq_loss.mask_prob training.best_rq_loss.mask_width  \\\n",
       "0                             0.01                             12.0   \n",
       "1                             0.01                             12.0   \n",
       "2                             0.01                             12.0   \n",
       "3                             0.01                             12.0   \n",
       "4                             0.01                             12.0   \n",
       "5                             0.01                             12.0   \n",
       "6                             0.01                             12.0   \n",
       "7                             0.01                             12.0   \n",
       "8                             0.01                             12.0   \n",
       "9                             0.01                             12.0   \n",
       "\n",
       "   training.best_rq_loss.codebook_size training.best_rq_loss.codebook_dim  \\\n",
       "0                               8192.0                               16.0   \n",
       "1                               8192.0                               16.0   \n",
       "2                               8192.0                               16.0   \n",
       "3                               8192.0                               16.0   \n",
       "4                               8192.0                               16.0   \n",
       "5                               8192.0                               16.0   \n",
       "6                               8192.0                               16.0   \n",
       "7                               8192.0                               16.0   \n",
       "8                               8192.0                               16.0   \n",
       "9                               8192.0                               16.0   \n",
       "\n",
       "  training.best_rq_loss.offset  training.best_rq_loss.speaker_regex  \\\n",
       "0                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "1                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "2                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "3                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "4                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "5                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "6                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "7                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "8                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "9                          0.0                     ^lbi-([^-]+)-.*$   \n",
       "\n",
       "   training.best_rq_loss.prediction_type  training.shuffle  \\\n",
       "0                                    csa             False   \n",
       "1                                    csa             False   \n",
       "2                                    csa             False   \n",
       "3                                    csa             False   \n",
       "4                                    csa             False   \n",
       "5                                    csa             False   \n",
       "6                                    csa             False   \n",
       "7                                    csa             False   \n",
       "8                                    csa             False   \n",
       "9                                    csa             False   \n",
       "\n",
       "   training.max_epochs  training.early_stopping_patience  \n",
       "0                  200                                10  \n",
       "1                  200                                10  \n",
       "2                  200                                10  \n",
       "3                  200                                10  \n",
       "4                  200                                10  \n",
       "5                  200                                10  \n",
       "6                  200                                10  \n",
       "7                  200                                10  \n",
       "8                  200                                10  \n",
       "9                  200                                10  \n",
       "\n",
       "[10 rows x 59 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dft = collate_data(\"tb\")\n",
    "dft.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tb.val_loss\n",
      "csa.max_width             \n",
      "2.0               1.948407\n",
      "4.0               1.882025\n",
      "8.0               1.931669\n",
      "16.0              1.954543\n",
      "32.0              1.921521\n",
      "64.0              2.017123\n",
      "128.0             1.978303\n"
     ]
    }
   ],
   "source": [
    "# regular training\n",
    "\n",
    "df = filter_data_equal(dft, {\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"training.cpc_loss.prediction_steps\": 12,\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"training.max_epochs\": 200,\n",
    "    \"train_part\": \"100\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ").copy()\n",
    "\n",
    "check_data(\n",
    "    df, \"tb.epoch\", \"tb.val_loss\", \"tb.step\", \"csa.max_width\"\n",
    ")\n",
    "# 5 seeds * 7 context windows\n",
    "assert len(pd.unique(df['name'])) == 5 * 7\n",
    "\n",
    "print(df[['csa.max_width', 'tb.val_loss']].groupby(['csa.max_width']).min())\n",
    "\n",
    "fig = plt.figure(figsize=[6.8, 4.8])\n",
    "plot = (\n",
    "    so.Plot(df, x=\"tb.epoch\", y=\"tb.val_loss\", color=\"csa.max_width\")\n",
    "    .limit(y=(1.9, 3.0), x=(0, 200))\n",
    "    .add(so.Line(), so.Agg())\n",
    "    .add(so.Band(), so.Est(errorbar=\"se\"), group=\"csa.max_width\")\n",
    "    .label(x=\"epoch\", y=\"CPC validation loss\", color=\"context width\")\n",
    "    .scale(\n",
    "        color=so.Continuous(trans=\"log\")\n",
    "            .tick(at=(2, 4, 8, 16, 32, 64, 128))\n",
    "            .label(like=\".0f\"))\n",
    "    .on(fig)\n",
    ")\n",
    "\n",
    "plot.plot()\n",
    "\n",
    "leg = fig.legends[0]\n",
    "bb = leg.get_bbox_to_anchor().transformed(fig.axes[0].transAxes.inverted())\n",
    "bb.x0 -= .335\n",
    "bb.y0 += .41\n",
    "leg.set_bbox_to_anchor(bb, transform=fig.axes[0].transAxes)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../resources/train_loss_vs_width.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tb.val_loss\n",
      "csa.max_width             \n",
      "2.0               1.866130\n",
      "4.0               1.859689\n",
      "8.0               1.884088\n",
      "16.0              1.840316\n",
      "32.0              1.792857\n",
      "64.0              1.825067\n",
      "128.0             1.803738\n"
     ]
    }
   ],
   "source": [
    "# long training\n",
    "df = filter_data_equal(dft, {\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"training.cpc_loss.prediction_steps\": 12,\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"training.max_epochs\": 500,\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ").copy()\n",
    "\n",
    "check_data(\n",
    "    df, \"tb.epoch\", \"tb.val_loss\", \"tb.step\", \"csa.max_width\"\n",
    ")\n",
    "# 7 context windows\n",
    "assert len(pd.unique(df['name'])) == 7\n",
    "\n",
    "print(df[['csa.max_width', 'tb.val_loss']].groupby(['csa.max_width']).min())\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=[6.8, 4.8])\n",
    "plot = (\n",
    "    so.Plot(df, x=\"tb.epoch\", y=\"tb.val_loss\", color=\"csa.max_width\")\n",
    "    .limit(y=(1.7, 3.0), x=(0, 500))\n",
    "    .add(so.Line(), so.Agg())\n",
    "    .label(x=\"epoch\", y=\"CPC validation loss\", color=\"context width\")\n",
    "    .scale(\n",
    "        color=so.Continuous(trans=\"log\")\n",
    "            .tick(at=(2, 4, 8, 16, 32, 64, 128))\n",
    "            .label(like=\".0f\"))\n",
    "    .on(fig)\n",
    ")\n",
    "\n",
    "plot.plot()\n",
    "\n",
    "leg = fig.legends[0]\n",
    "bb = leg.get_bbox_to_anchor().transformed(fig.axes[0].transAxes.inverted())\n",
    "bb.x0 -= .335\n",
    "bb.y0 += .41\n",
    "leg.set_bbox_to_anchor(bb, transform=fig.axes[0].transAxes)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../resources/train_loss_vs_width_long.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tb.val_loss\n",
      "csa.max_width             \n",
      "2.0               0.044562\n",
      "4.0               0.072279\n",
      "8.0               0.074398\n",
      "16.0              0.050661\n",
      "32.0              0.054660\n",
      "64.0              0.058745\n",
      "128.0             0.062200\n"
     ]
    }
   ],
   "source": [
    "# BEST-RQ training\n",
    "\n",
    "df = filter_data_equal(dft, {\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"best-rq\",\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"training.max_epochs\": 200,\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ").copy()\n",
    "\n",
    "check_data(\n",
    "    df, \"tb.epoch\", \"tb.val_loss\", \"tb.step\", \"csa.max_width\"\n",
    ")\n",
    "# 7 context windows\n",
    "assert len(pd.unique(df['name'])) == 7\n",
    "\n",
    "print(df[['csa.max_width', 'tb.val_loss']].groupby(['csa.max_width']).min())\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=[6.8, 4.8])\n",
    "plot = (\n",
    "    so.Plot(df, x=\"tb.epoch\", y=\"tb.val_loss\", color=\"csa.max_width\")\n",
    "    .limit(y=(0.03, 0.2), x=(0, 200))\n",
    "    .add(so.Line(), so.Agg())\n",
    "    .label(x=\"epoch\", y=\"BEST-RQ validation loss\", color=\"context width\")\n",
    "    .scale(\n",
    "        color=so.Continuous(trans=\"log\")\n",
    "            .tick(at=(2, 4, 8, 16, 32, 64, 128))\n",
    "            .label(like=\".0f\"))\n",
    "    .on(fig)\n",
    ")\n",
    "\n",
    "plot.plot()\n",
    "\n",
    "leg = fig.legends[0]\n",
    "bb = leg.get_bbox_to_anchor().transformed(fig.axes[0].transAxes.inverted())\n",
    "bb.x0 -= .335\n",
    "bb.y0 += .41\n",
    "leg.set_bbox_to_anchor(bb, transform=fig.axes[0].transAxes)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../resources/train_loss_vs_width_bestrq.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               tb.val_loss\n",
      "csa.max_width             \n",
      "8                 1.797562\n",
      "128               1.746895\n"
     ]
    }
   ],
   "source": [
    "# 960-hr training\n",
    "df = filter_data_equal(dft, {\n",
    "    \"conv.norm_type\": \"none\",\n",
    "    \"context_type\": \"csa\",\n",
    "    \"training.loss_type\": \"cpc\",\n",
    "    \"training.cpc_loss.gutted_steps\": 0,\n",
    "    'training.cpc_loss.averaging_penalty': 0,\n",
    "    \"training.cpc_loss.prediction_steps\": 12,\n",
    "    \"csa.dim_feedforward\": 1024,\n",
    "    \"csa.num_layers\": 1,\n",
    "    \"train_part\": \"960\",\n",
    "})\n",
    "df = filter_data_in(\n",
    "    df, {\"csa.max_width\": WIDTHS}\n",
    ").copy()\n",
    "\n",
    "check_data(\n",
    "    df, \"tb.epoch\", \"tb.val_loss\", \"tb.step\", \"csa.max_width\"\n",
    ")\n",
    "# 2 context windows\n",
    "assert len(pd.unique(df['name'])) == 2\n",
    "\n",
    "df['csa.max_width'] = df['csa.max_width'].astype('int')\n",
    "\n",
    "print(df[['csa.max_width', 'tb.val_loss']].groupby(['csa.max_width']).min())\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=[6.8, 4.8])\n",
    "plot = (\n",
    "    so.Plot(df, x=\"tb.epoch\", y=\"tb.val_loss\", color=\"csa.max_width\")\n",
    "    .limit(y=(1.7, 3.0), x=(0, 100))\n",
    "    .add(so.Line(), so.Agg())\n",
    "    .label(x=\"epoch\", y=\"CPC validation loss\", color=\"context width\")\n",
    "    .scale(\n",
    "        color=so.Nominal())\n",
    "    .on(fig)\n",
    ")\n",
    "\n",
    "plot.plot()\n",
    "\n",
    "leg = fig.legends[0]\n",
    "bb = leg.get_bbox_to_anchor().transformed(fig.axes[0].transAxes.inverted())\n",
    "bb.x0 -= .7\n",
    "bb.y0 += .4\n",
    "leg.set_bbox_to_anchor(bb, transform=fig.axes[0].transAxes)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('../resources/train_loss_vs_width_960.pdf')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_clean\n",
      "\tcpc.csa128/version_0101: lm_ord4_width32=19.9%, nolm_width32=31.9%,\n",
      "\tcpc.csa16/version_0103: lm_ord4_width32=19.4%, nolm_width32=30.9%,\n",
      "\tcpc.csa2/version_0105: lm_ord4_width32=19.1%, nolm_width32=30.3%,\n",
      "\tcpc.csa32/version_0104: lm_ord4_width32=18.1%, nolm_width32=30.8%,\n",
      "\tcpc.csa4/version_0102: lm_ord4_width32=16.5%, nolm_width32=26.5%,\n",
      "\tcpc.csa64/version_0101: lm_ord4_width32=22.7%, nolm_width32=34.3%,\n",
      "\tcpc.csa8/version_0101: lm_ord4_width32=17.0%, nolm_width32=29.8%,\n",
      "\tcpc.small/version_1: lm_ord2_width32=17.0%, lm_ord3_width32=15.1%, lm_ord4_width32=14.7%, nolm_width32=26.6%,\n",
      "dev_other\n",
      "\tcpc.csa128/version_0101: lm_ord4_width32=39.6%, nolm_width32=52.0%,\n",
      "\tcpc.csa16/version_0103: lm_ord4_width32=39.9%, nolm_width32=51.4%,\n",
      "\tcpc.csa2/version_0105: lm_ord4_width32=39.4%, nolm_width32=51.5%,\n",
      "\tcpc.csa32/version_0104: lm_ord4_width32=38.4%, nolm_width32=52.1%,\n",
      "\tcpc.csa4/version_0102: lm_ord4_width32=36.6%, nolm_width32=48.0%,\n",
      "\tcpc.csa64/version_0101: lm_ord4_width32=42.9%, nolm_width32=54.8%,\n",
      "\tcpc.csa8/version_0101: lm_ord4_width32=37.3%, nolm_width32=51.1%,\n",
      "\tcpc.small/version_1: lm_ord2_width32=38.9%, lm_ord3_width32=36.9%, lm_ord4_width32=36.4%, nolm_width32=50.3%,\n",
      "test_clean\n",
      "\tcpc.csa128/version_0101: lm_ord4_width32=18.9%, nolm_width32=30.7%,\n",
      "\tcpc.csa16/version_0103: lm_ord4_width32=17.9%, nolm_width32=29.1%,\n",
      "\tcpc.csa2/version_0105: lm_ord4_width32=18.0%, nolm_width32=28.9%,\n",
      "\tcpc.csa32/version_0104: lm_ord4_width32=17.1%, nolm_width32=29.3%,\n",
      "\tcpc.csa4/version_0102: lm_ord4_width32=15.4%, nolm_width32=25.1%,\n",
      "\tcpc.csa64/version_0101: lm_ord4_width32=21.3%, nolm_width32=33.2%,\n",
      "\tcpc.csa8/version_0101: lm_ord4_width32=16.1%, nolm_width32=27.7%,\n",
      "\tcpc.small/version_1: lm_ord2_width32=16.1%, lm_ord3_width32=14.5%, lm_ord4_width32=14.1%, nolm_width32=25.5%,\n",
      "test_other\n",
      "\tcpc.csa128/version_0101: lm_ord4_width32=44.2%, nolm_width32=55.5%,\n",
      "\tcpc.csa16/version_0103: lm_ord4_width32=43.9%, nolm_width32=55.2%,\n",
      "\tcpc.csa2/version_0105: lm_ord4_width32=43.9%, nolm_width32=55.6%,\n",
      "\tcpc.csa32/version_0104: lm_ord4_width32=42.6%, nolm_width32=55.8%,\n",
      "\tcpc.csa4/version_0102: lm_ord4_width32=41.0%, nolm_width32=51.8%,\n",
      "\tcpc.csa64/version_0101: lm_ord4_width32=48.5%, nolm_width32=58.7%,\n",
      "\tcpc.csa8/version_0101: lm_ord4_width32=40.9%, nolm_width32=54.7%,\n",
      "\tcpc.small/version_1: lm_ord2_width32=43.2%, lm_ord3_width32=41.2%, lm_ord4_width32=40.7%, nolm_width32=54.1%,\n"
     ]
    }
   ],
   "source": [
    "part2model2dname2wer = dict()\n",
    "for score_file in Path('../exp').glob('cpc.*/version_*/baseline/full_v2000/decoding/**/*.wer.txt'):\n",
    "    line = score_file.read_text().rstrip().split()\n",
    "    pth = Path(line[1][1:-1])\n",
    "    part = pth.parent.name\n",
    "    model = pth.parents[-3].name + '/' + pth.parents[-4].name\n",
    "    dname = pth.name[:-9]\n",
    "    part2model2dname2wer.setdefault(part, dict()).setdefault(model, dict())[dname] = line[-1]\n",
    "\n",
    "for (part, model2dname2wer) in sorted(part2model2dname2wer.items()):\n",
    "    print(part)\n",
    "    for model, dname2wer in sorted(model2dname2wer.items()):\n",
    "        print(f\"\\t{model}:\", end='')\n",
    "        for dname, wer in sorted(dname2wer.items()):\n",
    "            print(f\" {dname}={wer},\", end='')\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
